[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "I’m data analyst with R, SQL, Power BI, and Tableau, experience.\nI’m always eager to explore new topics and challenge myself by finding creative ways to apply my knowledge and skills in various contexts.\nCheck out some of my projects here."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Bio",
    "section": "",
    "text": "I’m a data analyst with experience in R, SQL, Power BI, and Tableau.\nI’m always eager to explore new topics and challenge myself by finding creative ways to apply my knowledge and skills in various contexts.\nCheck out some of my projects here.",
    "crumbs": [
      "About Me",
      "Bio"
    ]
  },
  {
    "objectID": "about.html#education",
    "href": "about.html#education",
    "title": "About",
    "section": "Education",
    "text": "Education\nUniversity of Brighton | Brighton, East Sussex MSc Data Analytics | Oct 2020 - Oct 2021\nUniversity of Leeds | Leeds, West Yorkshire  BA International Development | Sept 2011 - July 2014"
  },
  {
    "objectID": "about.html#experience",
    "href": "about.html#experience",
    "title": "About",
    "section": "Experience",
    "text": "Experience\nEnvironment Agency  Analyst | Aug 2023 - present   Leonardo Hotels Revenue Analyst | July 2022 - July 2023"
  },
  {
    "objectID": "about.html#hi-im-tan.",
    "href": "about.html#hi-im-tan.",
    "title": "About",
    "section": "",
    "text": "I’m data analyst with R, SQL, Power BI, and Tableau, experience.\nI’m always eager to explore new topics and challenge myself by finding creative ways to apply my knowledge and skills in various contexts.\nCheck out some of my projects here."
  },
  {
    "objectID": "index.html#hi-im-tan.",
    "href": "index.html#hi-im-tan.",
    "title": "Bio",
    "section": "",
    "text": "I’m a data analyst with experience in R, SQL, Power BI, and Tableau.\nI’m always eager to explore new topics and challenge myself by finding creative ways to apply my knowledge and skills in various contexts.\nCheck out some of my projects here.",
    "crumbs": [
      "About Me",
      "Bio"
    ]
  },
  {
    "objectID": "index.html#education",
    "href": "index.html#education",
    "title": "Bio",
    "section": "Education",
    "text": "Education\nUniversity of Brighton | Brighton, East Sussex MSc Data Analytics | Oct 2020 - Oct 2021\nUniversity of Leeds | Leeds, West Yorkshire  BA International Development | Sept 2011 - July 2014",
    "crumbs": [
      "About Me",
      "Bio"
    ]
  },
  {
    "objectID": "index.html#experience",
    "href": "index.html#experience",
    "title": "Bio",
    "section": "Experience",
    "text": "Experience\nEnvironment Agency | Worthing, West Sussex Analyst | Aug 2023 - present   Leonardo Hotels | Birmingham, West Midlands Revenue Analyst | July 2022 - July 2023",
    "crumbs": [
      "About Me",
      "Bio"
    ]
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "Time Series Analysis",
    "section": "",
    "text": "This time series analysis focuses on weekly data available from the Office for National Statistics (ONS). Revolut is one of a number of digital banks that have emerged in recent years and it has around 4.8 million users within the UK financial payment ecosystem. The bank has been providing data to the ONS since the start of the COVID-19 pandemic and the ONS indexes data at the average February 2020 spending level as a pre-pandemic baseline. They also apply a 7-day rolling average to the data to take into account any intra-week spending cyclicality.\nWhile this data is useful for analysing spending changes since 2020 it is important to note a number of limitations:\n\nRevolut customers tend to be younger and more metropolitan than the average UK consumer, so spending may not be representative of the overall UK macroeconomic picture.\nThe indices in the dataset do not take into account inflation and are presented on a nominal basis and are not adjusted for price increases over time. According to the ONS the CPI rate was at 1.8% in January 2020 but by January 2023 was at 10.1%.\nWithin the UK financial transaction ecosystem there has been a shift away from cash as a payment medium in favour of card spending. This results in indices being uplifted over time in areas where consumers replace low value cash transactions with low value card transactions instead. This is more likely to be true in this dataset given the demographic profile of Revolut customers.\n\nThe full background on methodology and limitations is available from the ONS here."
  },
  {
    "objectID": "projects/Dashboards/index.html",
    "href": "projects/Dashboards/index.html",
    "title": "Dashboards",
    "section": "",
    "text": "As well as my experience building corporate dashboards in Power BI and Tableau, I’m working on my R Shiny skills and have recently developed a dashboard exploring my parkrun times.\n\nParkrun Dashboard\n\n\n\nPakrun Dashboard\n\n\n\n\n\nPakrun Dashboard"
  },
  {
    "objectID": "projects/Gender_Pay_Gap/index.html",
    "href": "projects/Gender_Pay_Gap/index.html",
    "title": "Gender Pay Gap",
    "section": "",
    "text": "Introduction\nI used data from the UK Gender Pay Gap Service to highlight the gendered disparity in pay between men and women in the UK.\n\n\nMethodology\nThe dataset has almost 49,000 entries across 27 variables for each of the companies that made a submission. I chose to focus on the mean values in difference between hourly and bonus pay across genders for each entry.\nTo do this, I took the relevant mean values and post codes and essentially performed a lookup with a separate dataset of UK postcodes to obtain the local authority names. This dataframe was combined with a shapefile of UK local authorities. I was then able to summarise the data using the mean value in the differences per local authority.\n\n\nLimitations\nThis approach does have limitations, specifically by using mean values per local authority results in data that is not standardised. Neverthless, the intention of this small project was to put together a visualisation rather than conduct an in-depth analysis of the data.\n\n\nR Code\nThe full code is available on GitHub by clicking here.\n\n\n\nUK Paygap Data"
  },
  {
    "objectID": "projects/Time_Series_Analysis/index.html",
    "href": "projects/Time_Series_Analysis/index.html",
    "title": "Time Series Analysis",
    "section": "",
    "text": "This time series analysis focuses on weekly data available from the Office for National Statistics (ONS). Revolut is one of a number of digital banks that have emerged in recent years and it has around 4.8 million users within the UK financial payment ecosystem. The bank has been providing data to the ONS since the start of the COVID-19 pandemic and the ONS indexes data at the average February 2020 spending level as a pre-pandemic baseline. They also apply a 7-day rolling average to the data to take into account any intra-week spending cyclicality.\nWhile this data is useful for analysing spending changes since 2020 it is important to note a number of limitations:\n\nRevolut customers tend to be younger and more metropolitan than the average UK consumer, so spending may not be representative of the overall UK macroeconomic picture.\nThe indices in the dataset do not take into account inflation and are presented on a nominal basis and are not adjusted for price increases over time. According to the ONS the CPI rate was at 1.8% in January 2020 but by January 2023 was at 10.1%.\nWithin the UK financial transaction ecosystem there has been a shift away from cash as a payment medium in favour of card spending. This results in indices being uplifted over time in areas where consumers replace low value cash transactions with low value card transactions instead. This is more likely to be true in this dataset given the demographic profile of Revolut customers.\n\nThe full background on methodology and limitations is available from the ONS here."
  },
  {
    "objectID": "projects/Time_Series_Analysis/index.html#revolut-spending-data",
    "href": "projects/Time_Series_Analysis/index.html#revolut-spending-data",
    "title": "Time Series Analysis",
    "section": "",
    "text": "This time series analysis focuses on weekly data available from the Office for National Statistics (ONS). Revolut is one of a number of digital banks that have emerged in recent years and it has around 4.8 million users within the UK financial payment ecosystem. The bank has been providing data to the ONS since the start of the COVID-19 pandemic and the ONS indexes data at the average February 2020 spending level as a pre-pandemic baseline. They also apply a 7-day rolling average to the data to take into account any intra-week spending cyclicality.\nWhile this data is useful for analysing spending changes since 2020 it is important to note a number of limitations:\n\nRevolut customers tend to be younger and more metropolitan than the average UK consumer, so spending may not be representative of the overall UK macroeconomic picture.\nThe indices in the dataset do not take into account inflation and are presented on a nominal basis and are not adjusted for price increases over time. According to the ONS the CPI rate was at 1.8% in January 2020 but by January 2023 was at 10.1%.\nWithin the UK financial transaction ecosystem there has been a shift away from cash as a payment medium in favour of card spending. This results in indices being uplifted over time in areas where consumers replace low value cash transactions with low value card transactions instead. This is more likely to be true in this dataset given the demographic profile of Revolut customers.\n\nThe full background on methodology and limitations is available from the ONS here."
  },
  {
    "objectID": "projects/Time_Series_Analysis/index.html#time-series-analysis",
    "href": "projects/Time_Series_Analysis/index.html#time-series-analysis",
    "title": "Time Series Analysis",
    "section": "Time Series Analysis",
    "text": "Time Series Analysis\nThis project utilizes the indexed rolling 7-day average total spend value from the spending by sector data to identify trends and forecast 28 days ahead. For the analysis, I will use the following methods: exponential smoothing, ARIMA, and forecasting using Prophet.\nAfter some initial cleaning of dataset to ensure it is in the correct format to conduct time series analysis in R, figure 1 shows plot of the spending over time shows how these levels changed over the course of the pandemic.\n\n\n\n\n\n\n\n\n\nIn general, what we can see is a clear upward trend across the three years and some seasonality exhibited around August and December-January. While the initial lockdown might be easily identifiable by the sharp dip during Q1 2020, it may be helpful to provide a reminder of all the restrictions implemented during the pandemic, and the plot below adds further context.\nThe red lines are indicative of the main lockdowns and the restrictions imposed due to the emergence of the Omicron variant in late 2021. Although there were many stages of ‘unlocking’ of restrictions, I have chosen to highlight two key moments with green lines.\n\n\n\n\n\n\n\n\n\nThe first of these easing periods is the Eat Out To Help Out programme during August 2020 which offered discounted meals in pubs, restaurants, and other hospitality outlets to support the sector. The second is in February 2022 when official COVID-19 restrictions were ended under the Living With Covid Plan. As a result of these two interventions, we can clearly identify periods of sustained spending as people had greater freedom of movement in their daily lives.\nIn spite of this, plotting the years against each reveals patterns in the second half of the year, particularly through Q4, that are broadly similar.\n\n\n\n\n\n\n\n\n\n\nExponential Smoothing\n\nHolt’s method with trend\nFor this dataset I have chosen to experiment with the exponential smoothing method with trend and then later add in the seasonality component to determine if this improves the forecast.\n\nfit &lt;- rs3 |&gt;\n  model(\n    `Holt's method` = ETS(Total ~ error(\"A\") + trend(\"A\") + season(\"N\"))\n  )\nfabletools::report(fit)\n\nSeries: Total \nModel: ETS(A,A,N) \n  Smoothing parameters:\n    alpha = 0.9998998 \n    beta  = 0.7845457 \n\n  Initial states:\n     l[0]    b[0]\n 111.1182 2.71086\n\n  sigma^2:  1.4885\n\n     AIC     AICc      BIC \n8771.040 8771.092 8796.381 \n\n\nThis trended exponential smoothing model has a very high alpha value indicating that values in the past are given less weight than more recent values due to the exponential decaying built into the model. In addition, the beta value is high and this takes into changes in the data.\nPlotting the forecast of the next 28 days sees quite a steady decline in the mean value and quite a wide distribution across both the 80% and 95% intervals, with the lower and upper bounds of the 95% interval ranging below 0 and close to 300.\n\n\n\n\n\n\n\n\n\nGiven the macroeconomic conditions in the British economy are have not been particularly positive, this decline might not seem unreasonable and the model may benefit from the introduction of some level of dampening so as not to over-forecast.\n\nfit2 &lt;- rs3 |&gt;\n    model(`Damped Holt's method` = ETS(Total ~ error(\"A\") +\n                                         trend(\"Ad\") + season(\"N\"))\n    )\nfabletools::report(fit2)\n\nSeries: Total \nModel: ETS(A,Ad,N) \n  Smoothing parameters:\n    alpha = 0.9998987 \n    beta  = 0.8161713 \n    phi   = 0.8000001 \n\n  Initial states:\n     l[0]      b[0]\n 121.2629 -1.124004\n\n  sigma^2:  1.394\n\n     AIC     AICc      BIC \n8694.973 8695.045 8725.382 \n\n\nThe model estimates phi, the dampening coefficient, to be 0.80 and we see a slight decrease in the alpha and increase beta values. This dampened model also performs better compared top the previous model when we compare AIC, AICc, and BIC values. The table below compares the two models and we can see that the damped Holt’s method has a lower RMSE so makes it a better choice.\n\nrs3 |&gt; \n    model(\n        `Holt's method` = ETS(Total ~ error(\"A\") + trend(\"A\") + season(\"N\")),\n        `Damped Holt's method` = ETS(Total ~ error(\"A\") +\n                                         trend(\"Ad\") + season(\"N\"))\n        ) |&gt; accuracy()\n\n# A tibble: 2 × 10\n  .model              .type       ME  RMSE   MAE    MPE  MAPE  MASE RMSSE   ACF1\n  &lt;chr&gt;               &lt;chr&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n1 Holt's method       Trai… -0.00310  1.22 0.728 0.0164 0.742 0.144 0.175 0.0516\n2 Damped Holt's meth… Trai…  0.00414  1.18 0.689 0.0141 0.702 0.136 0.169 0.0136\n\n\nThe forecasts from the damped model also exhibit less variability in the 80% and 95% intervals than the earlier model.\n\n\n\n\n\n\n\n\n\nWhen comparing the two forecasts, the dampened forecast, unsurprisingly, decreases less rapidly or as extreme at the median value.\n\n\n\n\n\n\n\n\n\n\n\n\nHolt-Winters’ method with seasonality\nTo add in a seasonality component to the model we can use the Holt-Winters’ method either with an additive seasonality component, which assumes the seasonal variations within the time series to be approximately constant, or multiplicative seasonality component, where the assumption is that the variations are proportional to the level of the series.\nWith the initial modelling, we can see that the additive model performs better with its lower AIC, AICc, and BIC values, in addition to lower MSE and AMSE values.\n\n\n# A tibble: 2 × 9\n  .model           sigma2 log_lik   AIC  AICc   BIC   MSE  AMSE    MAE\n  &lt;chr&gt;             &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n1 Additive       1.78      -4483. 8990. 8990. 9051.  1.77  7.62 0.811 \n2 Multiplicative 0.000265  -4674. 9371. 9371. 9432.  2.83  9.74 0.0104\n\n\nThe difference between the two models is evident when forecasting the next 28 days, with the mean values for additive model increasing while the multiplicative model shows a decline.\n\n\n\n\n\n\n\n\n\nSimilarly, the RMSE for the additive model is better than multiplicative one, although it does not perform as well as the RMSE for the damped Holt’s method above.\n\n\n# A tibble: 2 × 10\n  .model         .type           ME  RMSE   MAE    MPE  MAPE  MASE RMSSE  ACF1\n  &lt;chr&gt;          &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 Additive       Training  0.000715  1.33 0.811 0.0304 0.827 0.161 0.191 0.323\n2 Multiplicative Training -0.00684   1.68 1.03  0.0278 1.04  0.203 0.242 0.374\n\n\nHowever, it is possible to combine the dampened trend method with both additive and multiplicative seasonality. Both models see a drop in MSE and the AIC, AICc, and BIC values fall significantly, with the dampened multiplicative Holt Winter’s method having very similar values to the dampened Holt’s method. The RMSE value improves but not to the extent that either model match the model using damped Holt’s method.\n\n\n# A tibble: 2 × 9\n  .model           sigma2 log_lik   AIC  AICc   BIC   MSE  AMSE     MAE\n  &lt;chr&gt;             &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;\n1 Additive       1.57      -4406. 8839. 8839. 8905.  1.55  6.04 0.749  \n2 Multiplicative 0.000157  -4368. 8762. 8762. 8827.  1.66  6.78 0.00786\n\n\n\n\n# A tibble: 2 × 10\n  .model         .type          ME  RMSE   MAE    MPE  MAPE  MASE RMSSE  ACF1\n  &lt;chr&gt;          &lt;chr&gt;       &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 Additive       Training 0.00681   1.25 0.749 0.0165 0.761 0.148 0.179 0.327\n2 Multiplicative Training 0.000218  1.29 0.778 0.0210 0.788 0.154 0.185 0.324\n\n\nThe plot here of the 28 day ahead forecast exhibits shallower increases for both models and a narrower set of intervals at 80% and 95%.\n\n\n\n\n\n\n\n\n\n\nModel selection\nHaving previously worked through a number of combinations of exponential smoothing models, both with and without dampening or seasonality, it seems that the damped Holt’s method without seasonality performed best when comparing AICc and RMSE values. However, it’s possible to employ the ETS() function in R to generate a model that minimises the AICc value.\n\n\nSeries: Total \nModel: ETS(M,Ad,N) \n  Smoothing parameters:\n    alpha = 0.9999 \n    beta  = 0.7938542 \n    phi   = 0.8000637 \n\n  Initial states:\n     l[0]      b[0]\n 116.3569 -5.895034\n\n  sigma^2:  1e-04\n\n     AIC     AICc      BIC \n8529.853 8529.925 8560.262 \n\n\nComparisons between this preferred model and the damped Holt’s model from earlier are below:\n\n\n# A tibble: 2 × 9\n  .model                 sigma2 log_lik   AIC  AICc   BIC   MSE  AMSE     MAE\n  &lt;chr&gt;                   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;\n1 R Preferred          0.000130  -4259. 8530. 8530. 8560.  1.33  6.13 0.00697\n2 Damped Holt's method 1.39      -4341. 8695. 8695. 8725.  1.39  6.17 0.689  \n\n\n\n\n# A tibble: 2 × 10\n  .model               .type      ME  RMSE   MAE    MPE  MAPE  MASE RMSSE   ACF1\n  &lt;chr&gt;                &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n1 R Preferred          Trai… 0.00912  1.15 0.684 0.0186 0.698 0.135 0.166 0.0745\n2 Damped Holt's method Trai… 0.00414  1.18 0.689 0.0141 0.702 0.136 0.169 0.0136\n\n\nThe output above tells us the model preferred by R uses Holt’s method where the error is multiplicative (rather than additive as has been used in the examples above), with an additive trend that is dampened. The value for alpha is very high, reflecting how the weight of the past observations decays quite rapidly. The AICc value is the lowest of all the models we have tested above.\nThe forecast of the next 28 days reflects the marginal decline exhibited in some of the other dampened models above. Given that the alpha value is relatively high it is not unsurprising that this model forecasts the mean value to be close to the total 7-day average spend in 2023.\n\n\n\n\n\n\n\n\n\nWe can use cross-validation based on a rolling forecasting origin, starting at the end of 2022 (chosen due to the impact of the pandemic prior to that) and increasing by one step each time. The result of this process is that the model preferred by R performs the best both when comparing AICc and RMSE.\n\n\n# A tibble: 2 × 9\n  .model                 sigma2 log_lik   AIC  AICc   BIC   MSE  AMSE     MAE\n  &lt;chr&gt;                   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;\n1 R Preferred          0.000130  -4259. 8530. 8530. 8560.  1.33  6.13 0.00697\n2 Damped Holt's method 1.39      -4341. 8695. 8695. 8725.  1.39  6.17 0.689  \n\n\n\n\n# A tibble: 2 × 10\n  .model               .type    ME  RMSE   MAE   MPE  MAPE  MASE RMSSE  ACF1\n  &lt;chr&gt;                &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 Damped Holt's method Test  0.841  9.92  7.73 0.492  5.58  1.53  1.43 0.979\n2 R Preferred          Test  0.912  9.77  7.66 0.544  5.53  1.52  1.40 0.979\n\n\nChecking the residuals of R’s preferred model, we can see that the innovation residuals appear to have a constant variance and mean of zero. The histogram exhibits some degree of normality although the peak is a little high. The ACF plot have a number of significant that decay exponentially.\n\n\n\n\n\n\n\n\n\nIn contrast to the damped Holt’s method model, while the residuals have a mean of zero, the variance does appear to increase as we reach the end of 2022 and start 2023. The histogram is slightly left-skewed and peaks so may also fail the normality test. The ACF plot bears some similarity to R’s preferred model with a number of significant lags and before decaying. Given this, R’s preferred model seems to be the better model.\n\n\n\n\n\n\n\n\n\n\n\n\nARIMA modelling\nLooking at the initial plot of data above, it is clear that the data is not stationary and the ACF plot below shows the same data when it is not differenced up to lag 100. The lags remain significant are taking a long time to decay because each is correlated to the previous one. This makes sense when we consider that each daily value in the dataset relates to rolling 7-day average spend so we would expect correlation between the current and previous values.\n\n\n\n\n\n\n\n\n\nTo make the data stationary, I have had to apply a log transformation to stabilise the variance and first order differencing to stabilise the mean. The resulting plot has a number of significant spikes around the time of lockdown restrictions being introduced, but overall resembles white noise.\n\n\n\n\n\n\n\n\n\nThe differenced ACF plot exhibits significant lags up to lag 6 before decaying away.\n\n\n\n\n\n\n\n\n\nIt is also possible to confirm stationarity of this differenced data with a KPSS unit root test, which gives a small test statistic and a p-value of 0.1 and allows us to assume the data is stationary:\n\n\n# A tibble: 1 × 2\n  kpss_stat kpss_pvalue\n      &lt;dbl&gt;       &lt;dbl&gt;\n1     0.139         0.1\n\n\nThe time plot and ACF & PACF plots of the stationary data are show below.\n\n\n\n\n\n\n\n\n\nGiven the data is a 7-day rolling average and that the ACF plot appears to show a sinusodial and seasonal pattern of aproximately 7 days, a seasonal ARIMA model would be appropriate. In order to achieve this, I will let R try to find the best model order. The first is the default stepwise procedure and the second one works harder to search for a better model.\n\nar_fit &lt;- rs3 |&gt; model(stepwise = ARIMA(Total),\n             search = ARIMA(Total, stepwise=FALSE, approx = FALSE))\n\nAs we can from the output here, R has ARIMA(3,1,0)(1,0,1)7 for both models\n\n\n# A mable: 2 x 2\n# Key:     Model name [2]\n  `Model name`                   Orders\n  &lt;chr&gt;                         &lt;model&gt;\n1 stepwise     &lt;ARIMA(3,1,0)(1,0,1)[7]&gt;\n2 search       &lt;ARIMA(3,1,0)(1,0,1)[7]&gt;\n\n\n\n\n# A tibble: 2 × 6\n  .model   sigma2 log_lik   AIC  AICc   BIC\n  &lt;chr&gt;     &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 stepwise  0.955  -1640. 3292. 3292. 3322.\n2 search    0.955  -1640. 3292. 3292. 3322.\n\n\nThe residuals, as shown below, appear to have a constant mean and variance in the time plot and the ACF, whilst show some spikes appears consistent with white noise. However, the model fails the Ljung-Box text for white noise. This model is still left-skewed and peaks a little too high in the histogram, thus failing the normality test.\n\n\n\n\n\n\n\n\n\n\n\n# A tibble: 1 × 3\n  .model lb_stat lb_pvalue\n  &lt;chr&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 search    133.   0.00420\n\n\nAlthough this model does not pass all of the residual tests we can still use it to forecast, bearing in mind the limitations concerning the accuracy of prediction intervals. Forecasts for the next 28 days are shown below.\n\n\n\n\n\n\n\n\n\n\n\nProphet\nFor an alternative approach, I have chosen to use Meta’s Prophet tool for forecasting time series data based on an additive model where non-linear trends are fit with yearly, weekly, and daily seasonality, plus holiday effects.\nIn order to use package, the dataset had to be modified so the date variable was renamed ‘ds’ and the total variable as ‘y’. In addition, Prophet allows for custom holidays to be added to the model to take into account national holidays that occur. The holidays function can also be used to deal with systemic shocks that would impact a time series so as to prevent the trend component capturing any peaks or troughs in the data. As such, I have created an additional tibble that holds the dates for the three UK lockdowns and the period of restrictions in place following the emergence of the omicron variant of COVID-19.\n\n\n# A tsibble: 5 x 2 [1D]\n  ds             y\n  &lt;date&gt;     &lt;dbl&gt;\n1 2020-01-01  114.\n2 2020-01-02  118.\n3 2020-01-03  118.\n4 2020-01-04  116.\n5 2020-01-05  114.\n\n\n\n\n# A tibble: 4 × 5\n  holiday    ds         lower_window ds_upper   upper_window\n  &lt;chr&gt;      &lt;date&gt;            &lt;dbl&gt; &lt;date&gt;            &lt;dbl&gt;\n1 lockdown_1 2020-03-26            0 2020-05-11            0\n2 lockdown_2 2020-11-05            0 2020-12-02            0\n3 lockdown_3 2021-01-05            0 2021-05-17            0\n4 omicron    2021-12-08            0 2022-02-24            0\n\n\nWith the data set up to, I started by modelling the time series with limited changes to the available parameters. However, the changepoint_prior_scale parameter was increased to make the trend more flexible and the seasonality mode changed from additive to multiplicative.\n\nm &lt;- prophet(df, changepoint.prior.scale = 0.3, holidays = lockdowns, seasonality.mode = \"multiplicative\")\n\nfuture &lt;- make_future_dataframe(m, periods = 28)\n\nforecast &lt;- predict(m, future)\n\nplot(m, forecast)+\n    labs(title = \"Prophet multiplicative model\",\n         y=\"Spend (£)\",\n        x=\"Date\")+\n  theme_bw()+\n  theme(plot.title = element_text(face=\"bold\"))\n\n\n\n\n\n\n\n\nThis interactive plot allows for the model to be viewed in more detail:\n\n\n\n\n\n\nUsing Prophet we are able to decompose the model and look at each component separately.\n\n\n\n\n\n\n\n\n\nFinally, using cross-validation we can measure forecast error against historical data in a method akin to a rolling forecast origin used earlier. With Prophet I have chosen to select an initial period of 400 days (i.e. up to early February 2021) and made predictions every 90 days for a forecast horizon of 28 days. Based on the current time series, this corresponded to 9 forecasts.\n\ndf.cv &lt;- cross_validation(m, initial = 400, period = 90, horizon = 28, units = 'days')\n\nOnce computed, we can visualise a range of statistics of prediction performance. In the plot below, the dots show the absolute percentage error and the blue line the mean absolute percentage error over the forecast horizon. Forecast error here remains up to 10% for the first 12 days but then steadily increases to a maximum of around 15% for predictions 28 days out.\n\n\n  horizon       mse      rmse       mae       mape      mdape      smape\n1  3 days  41.00205  6.403284  5.424640 0.05005081 0.04513999 0.05071951\n2  4 days  54.55002  7.385799  6.271378 0.05666009 0.04609069 0.05749919\n3  5 days  67.05754  8.188867  7.034154 0.06205384 0.05589260 0.06309027\n4  6 days  83.74800  9.151393  7.977976 0.06876534 0.06562857 0.07001672\n5  7 days 113.42346 10.650045  9.379767 0.07910440 0.07579380 0.08061358\n6  8 days 148.41528 12.182581 10.719817 0.08878131 0.08017642 0.09073356\n   coverage\n1 0.4355556\n2 0.3644444\n3 0.2933333\n4 0.2133333\n5 0.1422222\n6 0.1111111"
  },
  {
    "objectID": "projects1.html",
    "href": "projects1.html",
    "title": "R Shiny Dashboard",
    "section": "",
    "text": "As well as my experience building corporate dashboards in Power BI and Tableau, I’m working on my R Shiny skills and have recently developed a dashboard exploring my parkrun times.\n\nParkrun Dashboard\n\n\n\nPakrun Dashboard\n\n\n\n\n\nPakrun Dashboard",
    "crumbs": [
      "Projects",
      "R Shiny Dashboard"
    ]
  },
  {
    "objectID": "projects2.html",
    "href": "projects2.html",
    "title": "Gender Pay Gap Map",
    "section": "",
    "text": "Introduction\nI used data from the UK Gender Pay Gap Service to highlight the gendered disparity in pay between men and women in the UK.\n\n\nMethodology\nThe dataset has almost 49,000 entries across 27 variables for each of the companies that made a submission. I chose to focus on the mean values in difference between hourly and bonus pay across genders for each entry.\nTo do this, I took the relevant mean values and post codes and essentially performed a lookup with a separate dataset of UK postcodes to obtain the local authority names. This dataframe was combined with a shapefile of UK local authorities. I was then able to summarise the data using the mean value in the differences per local authority.\n\n\nLimitations\nThis approach does have limitations, specifically by using mean values per local authority results in data that is not standardised. Neverthless, the intention of this small project was to put together a visualisation rather than conduct an in-depth analysis of the data.\n\n\nR Code\nThe full code is available on GitHub by clicking here.",
    "crumbs": [
      "Projects",
      "Gender Pay Gap Map"
    ]
  },
  {
    "objectID": "projects.html#revolut-spending-data",
    "href": "projects.html#revolut-spending-data",
    "title": "Time Series Analysis",
    "section": "",
    "text": "This time series analysis focuses on weekly data available from the Office for National Statistics (ONS). Revolut is one of a number of digital banks that have emerged in recent years and it has around 4.8 million users within the UK financial payment ecosystem. The bank has been providing data to the ONS since the start of the COVID-19 pandemic and the ONS indexes data at the average February 2020 spending level as a pre-pandemic baseline. They also apply a 7-day rolling average to the data to take into account any intra-week spending cyclicality.\nWhile this data is useful for analysing spending changes since 2020 it is important to note a number of limitations:\n\nRevolut customers tend to be younger and more metropolitan than the average UK consumer, so spending may not be representative of the overall UK macroeconomic picture.\nThe indices in the dataset do not take into account inflation and are presented on a nominal basis and are not adjusted for price increases over time. According to the ONS the CPI rate was at 1.8% in January 2020 but by January 2023 was at 10.1%.\nWithin the UK financial transaction ecosystem there has been a shift away from cash as a payment medium in favour of card spending. This results in indices being uplifted over time in areas where consumers replace low value cash transactions with low value card transactions instead. This is more likely to be true in this dataset given the demographic profile of Revolut customers.\n\nThe full background on methodology and limitations is available from the ONS here."
  },
  {
    "objectID": "projects.html#time-series-analysis",
    "href": "projects.html#time-series-analysis",
    "title": "Time Series Analysis",
    "section": "Time Series Analysis",
    "text": "Time Series Analysis\nThis project utilizes the indexed rolling 7-day average total spend value from the spending by sector data to identify trends and forecast 28 days ahead. For the analysis, I will use the following methods: exponential smoothing, ARIMA, and forecasting using Prophet.\nAfter some initial cleaning of dataset to ensure it is in the correct format to conduct time series analysis in R, figure 1 shows plot of the spending over time shows how these levels changed over the course of the pandemic.\n\n\n\n\n\n\n\n\n\nIn general, what we can see is a clear upward trend across the three years and some seasonality exhibited around August and December-January. While the initial lockdown might be easily identifiable by the sharp dip during Q1 2020, it may be helpful to provide a reminder of all the restrictions implemented during the pandemic, and the plot below adds further context.\nThe red lines are indicative of the main lockdowns and the restrictions imposed due to the emergence of the Omicron variant in late 2021. Although there were many stages of ‘unlocking’ of restrictions, I have chosen to highlight two key moments with green lines.\n\n\n\n\n\n\n\n\n\nThe first of these easing periods is the Eat Out To Help Out programme during August 2020 which offered discounted meals in pubs, restaurants, and other hospitality outlets to support the sector. The second is in February 2022 when official COVID-19 restrictions were ended under the Living With Covid Plan. As a result of these two interventions, we can clearly identify periods of sustained spending as people had greater freedom of movement in their daily lives.\nIn spite of this, plotting the years against each reveals patterns in the second half of the year, particularly through Q4, that are broadly similar.\n\n\n\n\n\n\n\n\n\n\nExponential Smoothing\n\nHolt’s method with trend\nFor this dataset I have chosen to experiment with the exponential smoothing method with trend and then later add in the seasonality component to determine if this improves the forecast.\n\nfit &lt;- rs3 |&gt;\n  model(\n    `Holt's method` = ETS(Total ~ error(\"A\") + trend(\"A\") + season(\"N\"))\n  )\nfabletools::report(fit)\n\nSeries: Total \nModel: ETS(A,A,N) \n  Smoothing parameters:\n    alpha = 0.9998998 \n    beta  = 0.7845457 \n\n  Initial states:\n     l[0]    b[0]\n 111.1182 2.71086\n\n  sigma^2:  1.4885\n\n     AIC     AICc      BIC \n8771.040 8771.092 8796.381 \n\n\nThis trended exponential smoothing model has a very high alpha value indicating that values in the past are given less weight than more recent values due to the exponential decaying built into the model. In addition, the beta value is high and this takes into changes in the data.\nPlotting the forecast of the next 28 days sees quite a steady decline in the mean value and quite a wide distribution across both the 80% and 95% intervals, with the lower and upper bounds of the 95% interval ranging below 0 and close to 300.\n\n\n\n\n\n\n\n\n\nGiven the macroeconomic conditions in the British economy are have not been particularly positive, this decline might not seem unreasonable and the model may benefit from the introduction of some level of dampening so as not to over-forecast.\n\nfit2 &lt;- rs3 |&gt;\n    model(`Damped Holt's method` = ETS(Total ~ error(\"A\") +\n                                         trend(\"Ad\") + season(\"N\"))\n    )\nfabletools::report(fit2)\n\nSeries: Total \nModel: ETS(A,Ad,N) \n  Smoothing parameters:\n    alpha = 0.9998987 \n    beta  = 0.8161713 \n    phi   = 0.8000001 \n\n  Initial states:\n     l[0]      b[0]\n 121.2629 -1.124004\n\n  sigma^2:  1.394\n\n     AIC     AICc      BIC \n8694.973 8695.045 8725.382 \n\n\nThe model estimates phi, the dampening coefficient, to be 0.80 and we see a slight decrease in the alpha and increase beta values. This dampened model also performs better compared top the previous model when we compare AIC, AICc, and BIC values. The table below compares the two models and we can see that the damped Holt’s method has a lower RMSE so makes it a better choice.\n\nrs3 |&gt; \n    model(\n        `Holt's method` = ETS(Total ~ error(\"A\") + trend(\"A\") + season(\"N\")),\n        `Damped Holt's method` = ETS(Total ~ error(\"A\") +\n                                         trend(\"Ad\") + season(\"N\"))\n        ) |&gt; accuracy()\n\n# A tibble: 2 × 10\n  .model              .type       ME  RMSE   MAE    MPE  MAPE  MASE RMSSE   ACF1\n  &lt;chr&gt;               &lt;chr&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n1 Holt's method       Trai… -0.00310  1.22 0.728 0.0164 0.742 0.144 0.175 0.0516\n2 Damped Holt's meth… Trai…  0.00414  1.18 0.689 0.0141 0.702 0.136 0.169 0.0136\n\n\nThe forecasts from the damped model also exhibit less variability in the 80% and 95% intervals than the earlier model.\n\n\n\n\n\n\n\n\n\nWhen comparing the two forecasts, the dampened forecast, unsurprisingly, decreases less rapidly or as extreme at the median value.\n\n\n\n\n\n\n\n\n\n\n\n\nHolt-Winters’ method with seasonality\nTo add in a seasonality component to the model we can use the Holt-Winters’ method either with an additive seasonality component, which assumes the seasonal variations within the time series to be approximately constant, or multiplicative seasonality component, where the assumption is that the variations are proportional to the level of the series.\nWith the initial modelling, we can see that the additive model performs better with its lower AIC, AICc, and BIC values, in addition to lower MSE and AMSE values.\n\n\n# A tibble: 2 × 9\n  .model           sigma2 log_lik   AIC  AICc   BIC   MSE  AMSE    MAE\n  &lt;chr&gt;             &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n1 Additive       1.78      -4483. 8990. 8990. 9051.  1.77  7.62 0.811 \n2 Multiplicative 0.000265  -4674. 9371. 9371. 9432.  2.83  9.74 0.0104\n\n\nThe difference between the two models is evident when forecasting the next 28 days, with the mean values for additive model increasing while the multiplicative model shows a decline.\n\n\n\n\n\n\n\n\n\nSimilarly, the RMSE for the additive model is better than multiplicative one, although it does not perform as well as the RMSE for the damped Holt’s method above.\n\n\n# A tibble: 2 × 10\n  .model         .type           ME  RMSE   MAE    MPE  MAPE  MASE RMSSE  ACF1\n  &lt;chr&gt;          &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 Additive       Training  0.000715  1.33 0.811 0.0304 0.827 0.161 0.191 0.323\n2 Multiplicative Training -0.00684   1.68 1.03  0.0278 1.04  0.203 0.242 0.374\n\n\nHowever, it is possible to combine the dampened trend method with both additive and multiplicative seasonality. Both models see a drop in MSE and the AIC, AICc, and BIC values fall significantly, with the dampened multiplicative Holt Winter’s method having very similar values to the dampened Holt’s method. The RMSE value improves but not to the extent that either model match the model using damped Holt’s method.\n\n\n# A tibble: 2 × 9\n  .model           sigma2 log_lik   AIC  AICc   BIC   MSE  AMSE     MAE\n  &lt;chr&gt;             &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;\n1 Additive       1.57      -4406. 8839. 8839. 8905.  1.55  6.04 0.749  \n2 Multiplicative 0.000157  -4368. 8762. 8762. 8827.  1.66  6.78 0.00786\n\n\n\n\n# A tibble: 2 × 10\n  .model         .type          ME  RMSE   MAE    MPE  MAPE  MASE RMSSE  ACF1\n  &lt;chr&gt;          &lt;chr&gt;       &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 Additive       Training 0.00681   1.25 0.749 0.0165 0.761 0.148 0.179 0.327\n2 Multiplicative Training 0.000218  1.29 0.778 0.0210 0.788 0.154 0.185 0.324\n\n\nThe plot here of the 28 day ahead forecast exhibits shallower increases for both models and a narrower set of intervals at 80% and 95%.\n\n\n\n\n\n\n\n\n\n\nModel selection\nHaving previously worked through a number of combinations of exponential smoothing models, both with and without dampening or seasonality, it seems that the damped Holt’s method without seasonality performed best when comparing AICc and RMSE values. However, it’s possible to employ the ETS() function in R to generate a model that minimises the AICc value.\n\n\nSeries: Total \nModel: ETS(M,Ad,N) \n  Smoothing parameters:\n    alpha = 0.9999 \n    beta  = 0.7938542 \n    phi   = 0.8000637 \n\n  Initial states:\n     l[0]      b[0]\n 116.3569 -5.895034\n\n  sigma^2:  1e-04\n\n     AIC     AICc      BIC \n8529.853 8529.925 8560.262 \n\n\nComparisons between this preferred model and the damped Holt’s model from earlier are below:\n\n\n# A tibble: 2 × 9\n  .model                 sigma2 log_lik   AIC  AICc   BIC   MSE  AMSE     MAE\n  &lt;chr&gt;                   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;\n1 R Preferred          0.000130  -4259. 8530. 8530. 8560.  1.33  6.13 0.00697\n2 Damped Holt's method 1.39      -4341. 8695. 8695. 8725.  1.39  6.17 0.689  \n\n\n\n\n# A tibble: 2 × 10\n  .model               .type      ME  RMSE   MAE    MPE  MAPE  MASE RMSSE   ACF1\n  &lt;chr&gt;                &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n1 R Preferred          Trai… 0.00912  1.15 0.684 0.0186 0.698 0.135 0.166 0.0745\n2 Damped Holt's method Trai… 0.00414  1.18 0.689 0.0141 0.702 0.136 0.169 0.0136\n\n\nThe output above tells us the model preferred by R uses Holt’s method where the error is multiplicative (rather than additive as has been used in the examples above), with an additive trend that is dampened. The value for alpha is very high, reflecting how the weight of the past observations decays quite rapidly. The AICc value is the lowest of all the models we have tested above.\nThe forecast of the next 28 days reflects the marginal decline exhibited in some of the other dampened models above. Given that the alpha value is relatively high it is not unsurprising that this model forecasts the mean value to be close to the total 7-day average spend in 2023.\n\n\n\n\n\n\n\n\n\nWe can use cross-validation based on a rolling forecasting origin, starting at the end of 2022 (chosen due to the impact of the pandemic prior to that) and increasing by one step each time. The result of this process is that the model preferred by R performs the best both when comparing AICc and RMSE.\n\n\n# A tibble: 2 × 9\n  .model                 sigma2 log_lik   AIC  AICc   BIC   MSE  AMSE     MAE\n  &lt;chr&gt;                   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;\n1 R Preferred          0.000130  -4259. 8530. 8530. 8560.  1.33  6.13 0.00697\n2 Damped Holt's method 1.39      -4341. 8695. 8695. 8725.  1.39  6.17 0.689  \n\n\n\n\n# A tibble: 2 × 10\n  .model               .type    ME  RMSE   MAE   MPE  MAPE  MASE RMSSE  ACF1\n  &lt;chr&gt;                &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 Damped Holt's method Test  0.841  9.92  7.73 0.492  5.58  1.53  1.43 0.979\n2 R Preferred          Test  0.912  9.77  7.66 0.544  5.53  1.52  1.40 0.979\n\n\nChecking the residuals of R’s preferred model, we can see that the innovation residuals appear to have a constant variance and mean of zero. The histogram exhibits some degree of normality although the peak is a little high. The ACF plot have a number of significant that decay exponentially.\n\n\n\n\n\n\n\n\n\nIn contrast to the damped Holt’s method model, while the residuals have a mean of zero, the variance does appear to increase as we reach the end of 2022 and start 2023. The histogram is slightly left-skewed and peaks so may also fail the normality test. The ACF plot bears some similarity to R’s preferred model with a number of significant lags and before decaying. Given this, R’s preferred model seems to be the better model.\n\n\n\n\n\n\n\n\n\n\n\n\nARIMA modelling\nLooking at the initial plot of data above, it is clear that the data is not stationary and the ACF plot below shows the same data when it is not differenced up to lag 100. The lags remain significant are taking a long time to decay because each is correlated to the previous one. This makes sense when we consider that each daily value in the dataset relates to rolling 7-day average spend so we would expect correlation between the current and previous values.\n\n\n\n\n\n\n\n\n\nTo make the data stationary, I have had to apply a log transformation to stabilise the variance and first order differencing to stabilise the mean. The resulting plot has a number of significant spikes around the time of lockdown restrictions being introduced, but overall resembles white noise.\n\n\n\n\n\n\n\n\n\nThe differenced ACF plot exhibits significant lags up to lag 6 before decaying away.\n\n\n\n\n\n\n\n\n\nIt is also possible to confirm stationarity of this differenced data with a KPSS unit root test, which gives a small test statistic and a p-value of 0.1 and allows us to assume the data is stationary:\n\n\n# A tibble: 1 × 2\n  kpss_stat kpss_pvalue\n      &lt;dbl&gt;       &lt;dbl&gt;\n1     0.139         0.1\n\n\nThe time plot and ACF & PACF plots of the stationary data are show below.\n\n\n\n\n\n\n\n\n\nGiven the data is a 7-day rolling average and that the ACF plot appears to show a sinusodial and seasonal pattern of aproximately 7 days, a seasonal ARIMA model would be appropriate. In order to achieve this, I will let R try to find the best model order. The first is the default stepwise procedure and the second one works harder to search for a better model.\n\nar_fit &lt;- rs3 |&gt; model(stepwise = ARIMA(Total),\n             search = ARIMA(Total, stepwise=FALSE, approx = FALSE))\n\nAs we can from the output here, R has ARIMA(3,1,0)(1,0,1)7 for both models\n\n\n# A mable: 2 x 2\n# Key:     Model name [2]\n  `Model name`                   Orders\n  &lt;chr&gt;                         &lt;model&gt;\n1 stepwise     &lt;ARIMA(3,1,0)(1,0,1)[7]&gt;\n2 search       &lt;ARIMA(3,1,0)(1,0,1)[7]&gt;\n\n\n\n\n# A tibble: 2 × 6\n  .model   sigma2 log_lik   AIC  AICc   BIC\n  &lt;chr&gt;     &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 stepwise  0.955  -1640. 3292. 3292. 3322.\n2 search    0.955  -1640. 3292. 3292. 3322.\n\n\nThe residuals, as shown below, appear to have a constant mean and variance in the time plot and the ACF, whilst show some spikes appears consistent with white noise. However, the model fails the Ljung-Box text for white noise. This model is still left-skewed and peaks a little too high in the histogram, thus failing the normality test.\n\n\n\n\n\n\n\n\n\n\n\n# A tibble: 1 × 3\n  .model lb_stat lb_pvalue\n  &lt;chr&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 search    133.   0.00420\n\n\nAlthough this model does not pass all of the residual tests we can still use it to forecast, bearing in mind the limitations concerning the accuracy of prediction intervals. Forecasts for the next 28 days are shown below.\n\n\n\n\n\n\n\n\n\n\n\nProphet\nFor an alternative approach, I have chosen to use Meta’s Prophet tool for forecasting time series data based on an additive model where non-linear trends are fit with yearly, weekly, and daily seasonality, plus holiday effects.\nIn order to use package, the dataset had to be modified so the date variable was renamed ‘ds’ and the total variable as ‘y’. In addition, Prophet allows for custom holidays to be added to the model to take into account national holidays that occur. The holidays function can also be used to deal with systemic shocks that would impact a time series so as to prevent the trend component capturing any peaks or troughs in the data. As such, I have created an additional tibble that holds the dates for the three UK lockdowns and the period of restrictions in place following the emergence of the omicron variant of COVID-19.\n\n\n# A tsibble: 5 x 2 [1D]\n  ds             y\n  &lt;date&gt;     &lt;dbl&gt;\n1 2020-01-01  114.\n2 2020-01-02  118.\n3 2020-01-03  118.\n4 2020-01-04  116.\n5 2020-01-05  114.\n\n\n\n\n# A tibble: 4 × 5\n  holiday    ds         lower_window ds_upper   upper_window\n  &lt;chr&gt;      &lt;date&gt;            &lt;dbl&gt; &lt;date&gt;            &lt;dbl&gt;\n1 lockdown_1 2020-03-26            0 2020-05-11            0\n2 lockdown_2 2020-11-05            0 2020-12-02            0\n3 lockdown_3 2021-01-05            0 2021-05-17            0\n4 omicron    2021-12-08            0 2022-02-24            0\n\n\nWith the data set up to, I started by modelling the time series with limited changes to the available parameters. However, the changepoint_prior_scale parameter was increased to make the trend more flexible and the seasonality mode changed from additive to multiplicative.\n\nm &lt;- prophet(df, changepoint.prior.scale = 0.3, holidays = lockdowns, seasonality.mode = \"multiplicative\")\n\nfuture &lt;- make_future_dataframe(m, periods = 28)\n\nforecast &lt;- predict(m, future)\n\nplot(m, forecast)+\n    labs(title = \"Prophet multiplicative model\",\n         y=\"Spend (£)\",\n        x=\"Date\")+\n  theme_bw()+\n  theme(plot.title = element_text(face=\"bold\"))\n\n\n\n\n\n\n\n\nThis interactive plot allows for the model to be viewed in more detail:\n\n\n\n\n\n\nUsing Prophet we are able to decompose the model and look at each component separately.\n\n\n\n\n\n\n\n\n\nFinally, using cross-validation we can measure forecast error against historical data in a method akin to a rolling forecast origin used earlier. With Prophet I have chosen to select an initial period of 400 days (i.e. up to early February 2021) and made predictions every 90 days for a forecast horizon of 28 days. Based on the current time series, this corresponded to 9 forecasts.\n\ndf.cv &lt;- cross_validation(m, initial = 400, period = 90, horizon = 28, units = 'days')\n\nOnce computed, we can visualise a range of statistics of prediction performance. In the plot below, the dots show the absolute percentage error and the blue line the mean absolute percentage error over the forecast horizon. Forecast error here remains up to 10% for the first 12 days but then steadily increases to a maximum of around 15% for predictions 28 days out.\n\n\n  horizon       mse      rmse       mae       mape      mdape      smape\n1  3 days  41.00205  6.403284  5.424640 0.05005081 0.04513999 0.05071951\n2  4 days  54.55002  7.385799  6.271378 0.05666009 0.04609069 0.05749919\n3  5 days  67.05754  8.188867  7.034154 0.06205384 0.05589260 0.06309027\n4  6 days  83.74800  9.151393  7.977976 0.06876534 0.06562857 0.07001672\n5  7 days 113.42346 10.650045  9.379767 0.07910440 0.07579380 0.08061358\n6  8 days 148.41528 12.182581 10.719817 0.08878131 0.08017642 0.09073356\n   coverage\n1 0.4355556\n2 0.3644444\n3 0.2933333\n4 0.2133333\n5 0.1422222\n6 0.1111111"
  },
  {
    "objectID": "guides.html",
    "href": "guides.html",
    "title": "Guides",
    "section": "",
    "text": "How to pivot datasets\n\n\nA guide to using pivot_longer() and pivot_wider() in {tidyr}\n\n\n\n\n\n\n\nNo matching items",
    "crumbs": [
      "Reference",
      "Guides"
    ]
  },
  {
    "objectID": "posts/08-06-2024-pivoting/index.html",
    "href": "posts/08-06-2024-pivoting/index.html",
    "title": "How to pivot datasets",
    "section": "",
    "text": "Why, oh why?\nI’ve spent quite a few years working with data in R but was reminded of the brain fog that overcomes me each time I want to pivot any data when I saw Jörn’s post on Bluesky:\nWill ever I be able to convert data between wide and long format in #rstats without googling?— Jörn Alexander Quent (@jaquent.bsky.social) Jun 6, 2024 at 7:40\nI regularly use Excel and Power BI at work and pivoting can be pretty simple in Power Query (here’s the answer in case you’re wondering) but this site is a Microsoft-free zone so I’ll show you how to do in RStudio.\n\n\nEnter the Tidyverse\nFor this guide we’re using the {tidyr} package from {tidyverse} so let’s get them loaded up and set up a dataset for use in this guide:\n\nlibrary(tidyverse)\n\n\nindex &lt;- seq(1:10)\np1 &lt;- runif(10,1,50)\np2 &lt;- runif(10,5,70)\np3 &lt;- runif(10,7,90)\ndf &lt;- tibble(index,p1,p2,p3)\nprint(df)\n\n# A tibble: 10 × 4\n   index    p1    p2    p3\n   &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1     1 44.4   66.3  60.5\n 2     2 25.0   29.9  73.2\n 3     3  4.50  69.8  34.7\n 4     4 12.3   46.0  13.0\n 5     5 32.1   20.2  78.4\n 6     6 41.9   62.4  22.2\n 7     7 13.1   41.9  52.8\n 8     8 18.3   33.7  33.7\n 9     9 16.5   52.8  37.5\n10    10 26.5   63.3  28.3\n\n\nNow, let’s say we want to everything apart from the index column to be reshaped into a longer tibble where the p labels are in a column called class and the actual observations for each row are in a column called values. Using the pivot_longer() function we could do something like this were we select everything apart from index and column names are assigned using the names_to argument and values using values_to:\n\ndf |&gt; \n  pivot_longer(!index, \n               names_to = \"class\", \n               values_to = \"value\")\n\n# A tibble: 30 × 3\n   index class value\n   &lt;int&gt; &lt;chr&gt; &lt;dbl&gt;\n 1     1 p1    44.4 \n 2     1 p2    66.3 \n 3     1 p3    60.5 \n 4     2 p1    25.0 \n 5     2 p2    29.9 \n 6     2 p3    73.2 \n 7     3 p1     4.50\n 8     3 p2    69.8 \n 9     3 p3    34.7 \n10     4 p1    12.3 \n# ℹ 20 more rows\n\n\nOther ways of achieving this same result are by selecting specific columns from their column index; {tidyselect}’s selection helpers; or a regexp using the names_pattern argument:\n\n# Use column index to select columns\ndf |&gt; \n  pivot_longer(cols = c(2:4),\n               names_to = \"class\",\n               values_to = \"values\")\n\n\n# Use starts_with to select columns\ndf |&gt; \n  pivot_longer(cols = starts_with(\"p\"),\n               names_to = \"class\",\n               values_to = \"values\")\n\n# Use a regexp to select columns\ndf |&gt; \n  pivot_longer(cols = c(2:4),\n               names_to = \"class\",\n               names_pattern = \"^p(.*)\",\n               values_to = \"values\")\n\nNow let’s say that we have the same data in a long format, using df2, but want to use it in a wide format.\n\ndf2 &lt;- df |&gt; \n  pivot_longer(cols = starts_with(\"p\"),\n               names_to = \"class\",\n               values_to = \"values\")\n\nhead(df2,5)\n\n# A tibble: 5 × 3\n  index class values\n  &lt;int&gt; &lt;chr&gt;  &lt;dbl&gt;\n1     1 p1      44.4\n2     1 p2      66.3\n3     1 p3      60.5\n4     2 p1      25.0\n5     2 p2      29.9\n\n\nIn this case, we use pivot_wider() and the names_from argument to specify which column will be used for the column names, and values_from for the values.\n\ndf2 |&gt; \n  pivot_wider(names_from = class, \n              values_from = values)\n\n# A tibble: 10 × 4\n   index    p1    p2    p3\n   &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1     1 44.4   66.3  60.5\n 2     2 25.0   29.9  73.2\n 3     3  4.50  69.8  34.7\n 4     4 12.3   46.0  13.0\n 5     5 32.1   20.2  78.4\n 6     6 41.9   62.4  22.2\n 7     7 13.1   41.9  52.8\n 8     8 18.3   33.7  33.7\n 9     9 16.5   52.8  37.5\n10    10 26.5   63.3  28.3\n\n\n\n\nNext steps\nThe code above returns the simple tibble we started with but reshaping more complicated datasets might require the use of names_repair, names_sep, or names_expand arguments in pivot_wider. To learn about these and other arguments for both of the pivoting functions mentioned above then take a look at the detailed guide here. Happy pivoting!"
  },
  {
    "objectID": "projects/voter_reg/Voter registration.html",
    "href": "projects/voter_reg/Voter registration.html",
    "title": "Election voter registration",
    "section": "",
    "text": "General election 2024\nThis general election seems like it will be the most significant result since 1997 with Labour gaining a sizeable majority after fourteen years of Conservative rule. Rather than look at polls, I thought it would be interesting to explore who has registered to vote over the past four weeks since the election was called.\nThe Department for Levelling Up, Housing, and Communities (DLUHC) has a performance dashboard with all the relevant data available for this brief analysis.\n\n\nThe last 24 hours\nLet’s start with the last 24 hours before registration closed. The DLUHC dashboard records the number of voter registration applications submitted in a 5-minute period for its live service usage report. I downloaded the data shortly after midnight to get a view of the full day’s applications and the plot looks something like this:\n\n\n\n\n\n\n\n\n\nI wanted to understand what caused some of those spikes and used my own experience and did some investigation to come up with some answers.\n\n6-8am\nIt’s difficult to see on the chart above, but the underlying data shows these occurred in the 5-10 minutes after 6am, 6:30am, 7am, etc. There’s no details on the dashboard suggesting that there is a lag so my assumption here is that this two-hour window is typically when people have just woken up and, after either browsing online media or switching on the TV, have been reminded that June 18th was the last day to register to vote in the general election and did so before getting on with the rest of their day.\n\n\n9-10am\nThere’s a bit of a dip before two further prominent spikes that happen just after 9am and again just after 10am. I couldn’t find details of anything that might have prompted these. So my assumption here is that between the last spike just after 8am and the one at 9am, people are getting ready for work, dropping kids off at school, commuting, etc. So it is only at 9am when when they either start work or, if not working, see a reminder on one of the daytime TV shows to register to vote. This latter point may especially be true for the 10:15am spike in registrations since it occurs just after This Morning starts at 10am.\n\n\nLunchtime\nAt around 12 noon, TikTok sends out a push notification to its users reminding them to register and has been attributed as contributing to the increae in registrations.\n\n\n5pm\nAs many people were probably finishing their workday, Jeremy Corbyn, the now expelled Labour MP and former party leader at the 2019 general election, posted this tweet just after 5pm:\nUnfortunately, a tabloid newspaper has got hold of a music video I recorded in Islington North with an iconic grime artist I've admired for years.They are planning to publish a heavily edited clip, so I'm releasing the full version myself. Watch here: https://t.co/vwNGQN2wqU— Jeremy Corbyn (@jeremycorbyn) June 18, 2024 \nOf course, it was a spurious claim and the link took people to the voter registration site. It was one of a number of similar tweets in the the run up to June 18th and Corbyn received 4 million views, 59K likes, and 15K retweets but hardly registers as a spike in registrations. That said, it occurs just as there is a significant upward trend in numbers.\n\n\n6-8pm\nThe evening is pretty chaotic with evening TV news from 6pm reporting on the election latest and reminding viewers that the day was the last day to register to vote in time for the election. Sky News also published an article about the deadline and, I understand may have sent a notification to users of its app about it:\nThe deadline to register to vote in the general election is today.Here's everything you need to know about how to do it 👇 https://t.co/s98MGwEMw2— Sky News (@SkyNews) June 18, 2024 \nChannel 4 News also hosted a debate with leaders of some of the main parties from 6.30pm - 8pm. At around 7.30pm, the Apple News app on iPhones sent out a notification to users linking to an article about the deadline to register to vote.\n\n\n10.30pm\nRegistrations remain fairly consistent from around 8pm through till 10:30pm when we see a final peak before registrations drop-off by midnight. I’ve not been able to establish what might have caused registration to rise so much other than social media reminders that created a sense of urgency about the imminent deadline. Perhaps, this combined with a captive audience on their phone at bedtime was the right combination to give registrations one final push.\n\n\n\nTotal deadline day registrations\nThe final number of registrations was 629,878 and as you can see from the chart of cumulative registrations, between 7am and midnight, there was a consistent and steady upward trend.\n\n\n\n\n\n\n\n\n\nMy reading of this is that there was no single event that necessarily caused the registrations to spike, but the effect of regular reminders drove momentum. I take this view on the basis that there is no plateau at any point in the day in the cumulative numbers apart from the early hours of the morning.\nHow does this compare to the last election in 2019? Well, I can’t perform a similar analysis of the final day since the data is not available but, according to DLUHC, the total number of applications received on November 26 2019 was 640,815, the equivalent of 1.7% more registrations when compared to 2024.\n\n\n2024 vs 2019 voter registrations\nAlthough a comparison of the two deadline days is not possible, we can compare the number of registrations over the period between the election being announced and the last day voters can register to vote. In 2024 this period lasted 28 days while in 2019 it was 29 days long so I’ve dropped the first day in 2019 ot make the periods line up.\nNevertheless, we see a remarkably similar trend over the four weeks:\n\n\n\n\n\n\n\n\n\nFor both elections, we see an inital flurry of registrations over the first few days before numbers stabilise with similar numbers for each year until final days of the registration period. Apart from this, we see a significant spikes in the fourth week - what could have caused them? There’s not just one reason that can be attributed to these jumps in registrations but here are some of the events that occurred around those dates:\n\nIn 2024, the spike is on day 23 which was June 13, the day when Labour launched its manifesto and ITV held the first debate with representatives of seven parties.\nIn 2019, this spike occurred on day 24 which was November 22, and was the day of a debate on BBC Question Time between the main party leaders and the day after Labour’s manifesto launch. We also see a smaller spike on day 14 - November 12 - of the 2019 election. A number of things happened on that day, including a cyber attack on the Labour party’s IT systems and major flooding in northern England. However, the key political event likely to have caused the increase was the decision by Nigel Farage’s Brexit Party to withdraw candidates in constituencies where the Conservatives had won seats in the 2017 election.\n\n\n\n2024 vs 2019 voter registration demographics\nFinally, let’s take a look at how 2024 has compared to 2019’s voter registration demographics.\n\n20242019"
  },
  {
    "objectID": "projects/projects1.html",
    "href": "projects/projects1.html",
    "title": "R Shiny Dashboard",
    "section": "",
    "text": "As well as my experience building corporate dashboards in Power BI and Tableau, I’m working on my R Shiny skills and have recently developed a dashboard exploring my parkrun times.\n\nParkrun Dashboard\n\n\n\nPakrun Dashboard\n\n\n\n\n\nPakrun Dashboard",
    "crumbs": [
      "Projects",
      "R Shiny Dashboard"
    ]
  },
  {
    "objectID": "projects/projects.html",
    "href": "projects/projects.html",
    "title": "Time Series Analysis",
    "section": "",
    "text": "This time series analysis focuses on weekly data available from the Office for National Statistics (ONS). Revolut is one of a number of digital banks that have emerged in recent years and it has around 4.8 million users within the UK financial payment ecosystem. The bank has been providing data to the ONS since the start of the COVID-19 pandemic and the ONS indexes data at the average February 2020 spending level as a pre-pandemic baseline. They also apply a 7-day rolling average to the data to take into account any intra-week spending cyclicality.\nWhile this data is useful for analysing spending changes since 2020 it is important to note a number of limitations:\n\nRevolut customers tend to be younger and more metropolitan than the average UK consumer, so spending may not be representative of the overall UK macroeconomic picture.\nThe indices in the dataset do not take into account inflation and are presented on a nominal basis and are not adjusted for price increases over time. According to the ONS the CPI rate was at 1.8% in January 2020 but by January 2023 was at 10.1%.\nWithin the UK financial transaction ecosystem there has been a shift away from cash as a payment medium in favour of card spending. This results in indices being uplifted over time in areas where consumers replace low value cash transactions with low value card transactions instead. This is more likely to be true in this dataset given the demographic profile of Revolut customers.\n\nThe full background on methodology and limitations is available from the ONS here.",
    "crumbs": [
      "Projects",
      "Time Series Analysis"
    ]
  },
  {
    "objectID": "projects/projects.html#revolut-spending-data",
    "href": "projects/projects.html#revolut-spending-data",
    "title": "Time Series Analysis",
    "section": "",
    "text": "This time series analysis focuses on weekly data available from the Office for National Statistics (ONS). Revolut is one of a number of digital banks that have emerged in recent years and it has around 4.8 million users within the UK financial payment ecosystem. The bank has been providing data to the ONS since the start of the COVID-19 pandemic and the ONS indexes data at the average February 2020 spending level as a pre-pandemic baseline. They also apply a 7-day rolling average to the data to take into account any intra-week spending cyclicality.\nWhile this data is useful for analysing spending changes since 2020 it is important to note a number of limitations:\n\nRevolut customers tend to be younger and more metropolitan than the average UK consumer, so spending may not be representative of the overall UK macroeconomic picture.\nThe indices in the dataset do not take into account inflation and are presented on a nominal basis and are not adjusted for price increases over time. According to the ONS the CPI rate was at 1.8% in January 2020 but by January 2023 was at 10.1%.\nWithin the UK financial transaction ecosystem there has been a shift away from cash as a payment medium in favour of card spending. This results in indices being uplifted over time in areas where consumers replace low value cash transactions with low value card transactions instead. This is more likely to be true in this dataset given the demographic profile of Revolut customers.\n\nThe full background on methodology and limitations is available from the ONS here.",
    "crumbs": [
      "Projects",
      "Time Series Analysis"
    ]
  },
  {
    "objectID": "projects/projects.html#time-series-analysis",
    "href": "projects/projects.html#time-series-analysis",
    "title": "Time Series Analysis",
    "section": "Time Series Analysis",
    "text": "Time Series Analysis\nThis project utilizes the indexed rolling 7-day average total spend value from the spending by sector data to identify trends and forecast 28 days ahead. For the analysis, I will use the following methods: exponential smoothing, ARIMA, and forecasting using Prophet.\nAfter some initial cleaning of dataset to ensure it is in the correct format to conduct time series analysis in R, figure 1 shows plot of the spending over time shows how these levels changed over the course of the pandemic.\n\n\n\n\n\n\n\n\n\nIn general, what we can see is a clear upward trend across the three years and some seasonality exhibited around August and December-January. While the initial lockdown might be easily identifiable by the sharp dip during Q1 2020, it may be helpful to provide a reminder of all the restrictions implemented during the pandemic, and the plot below adds further context.\nThe red lines are indicative of the main lockdowns and the restrictions imposed due to the emergence of the Omicron variant in late 2021. Although there were many stages of ‘unlocking’ of restrictions, I have chosen to highlight two key moments with green lines.\n\n\n\n\n\n\n\n\n\nThe first of these easing periods is the Eat Out To Help Out programme during August 2020 which offered discounted meals in pubs, restaurants, and other hospitality outlets to support the sector. The second is in February 2022 when official COVID-19 restrictions were ended under the Living With Covid Plan. As a result of these two interventions, we can clearly identify periods of sustained spending as people had greater freedom of movement in their daily lives.\nIn spite of this, plotting the years against each reveals patterns in the second half of the year, particularly through Q4, that are broadly similar.\n\n\n\n\n\n\n\n\n\n\nExponential Smoothing\n\nHolt’s method with trend\nFor this dataset I have chosen to experiment with the exponential smoothing method with trend and then later add in the seasonality component to determine if this improves the forecast.\n\nfit &lt;- rs3 |&gt;\n  model(\n    `Holt's method` = ETS(Total ~ error(\"A\") + trend(\"A\") + season(\"N\"))\n  )\nfabletools::report(fit)\n\nSeries: Total \nModel: ETS(A,A,N) \n  Smoothing parameters:\n    alpha = 0.9998998 \n    beta  = 0.7845457 \n\n  Initial states:\n     l[0]    b[0]\n 111.1182 2.71086\n\n  sigma^2:  1.4885\n\n     AIC     AICc      BIC \n8771.040 8771.092 8796.381 \n\n\nThis trended exponential smoothing model has a very high alpha value indicating that values in the past are given less weight than more recent values due to the exponential decaying built into the model. In addition, the beta value is high and this takes into changes in the data.\nPlotting the forecast of the next 28 days sees quite a steady decline in the mean value and quite a wide distribution across both the 80% and 95% intervals, with the lower and upper bounds of the 95% interval ranging below 0 and close to 300.\n\n\n\n\n\n\n\n\n\nGiven the macroeconomic conditions in the British economy are have not been particularly positive, this decline might not seem unreasonable and the model may benefit from the introduction of some level of dampening so as not to over-forecast.\n\nfit2 &lt;- rs3 |&gt;\n    model(`Damped Holt's method` = ETS(Total ~ error(\"A\") +\n                                         trend(\"Ad\") + season(\"N\"))\n    )\nfabletools::report(fit2)\n\nSeries: Total \nModel: ETS(A,Ad,N) \n  Smoothing parameters:\n    alpha = 0.9998987 \n    beta  = 0.8161713 \n    phi   = 0.8000001 \n\n  Initial states:\n     l[0]      b[0]\n 121.2629 -1.124004\n\n  sigma^2:  1.394\n\n     AIC     AICc      BIC \n8694.973 8695.045 8725.382 \n\n\nThe model estimates phi, the dampening coefficient, to be 0.80 and we see a slight decrease in the alpha and increase beta values. This dampened model also performs better compared top the previous model when we compare AIC, AICc, and BIC values. The table below compares the two models and we can see that the damped Holt’s method has a lower RMSE so makes it a better choice.\n\nrs3 |&gt; \n    model(\n        `Holt's method` = ETS(Total ~ error(\"A\") + trend(\"A\") + season(\"N\")),\n        `Damped Holt's method` = ETS(Total ~ error(\"A\") +\n                                         trend(\"Ad\") + season(\"N\"))\n        ) |&gt; accuracy()\n\n# A tibble: 2 × 10\n  .model              .type       ME  RMSE   MAE    MPE  MAPE  MASE RMSSE   ACF1\n  &lt;chr&gt;               &lt;chr&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n1 Holt's method       Trai… -0.00310  1.22 0.728 0.0164 0.742 0.144 0.175 0.0516\n2 Damped Holt's meth… Trai…  0.00414  1.18 0.689 0.0141 0.702 0.136 0.169 0.0136\n\n\nThe forecasts from the damped model also exhibit less variability in the 80% and 95% intervals than the earlier model.\n\n\n\n\n\n\n\n\n\nWhen comparing the two forecasts, the dampened forecast, unsurprisingly, decreases less rapidly or as extreme at the median value.\n\n\n\n\n\n\n\n\n\n\n\n\nHolt-Winters’ method with seasonality\nTo add in a seasonality component to the model we can use the Holt-Winters’ method either with an additive seasonality component, which assumes the seasonal variations within the time series to be approximately constant, or multiplicative seasonality component, where the assumption is that the variations are proportional to the level of the series.\nWith the initial modelling, we can see that the additive model performs better with its lower AIC, AICc, and BIC values, in addition to lower MSE and AMSE values.\n\n\n# A tibble: 2 × 9\n  .model           sigma2 log_lik   AIC  AICc   BIC   MSE  AMSE    MAE\n  &lt;chr&gt;             &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n1 Additive       1.78      -4483. 8990. 8990. 9051.  1.77  7.62 0.811 \n2 Multiplicative 0.000265  -4674. 9371. 9371. 9432.  2.83  9.74 0.0104\n\n\nThe difference between the two models is evident when forecasting the next 28 days, with the mean values for additive model increasing while the multiplicative model shows a decline.\n\n\n\n\n\n\n\n\n\nSimilarly, the RMSE for the additive model is better than multiplicative one, although it does not perform as well as the RMSE for the damped Holt’s method above.\n\n\n# A tibble: 2 × 10\n  .model         .type           ME  RMSE   MAE    MPE  MAPE  MASE RMSSE  ACF1\n  &lt;chr&gt;          &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 Additive       Training  0.000715  1.33 0.811 0.0304 0.827 0.161 0.191 0.323\n2 Multiplicative Training -0.00684   1.68 1.03  0.0278 1.04  0.203 0.242 0.374\n\n\nHowever, it is possible to combine the dampened trend method with both additive and multiplicative seasonality. Both models see a drop in MSE and the AIC, AICc, and BIC values fall significantly, with the dampened multiplicative Holt Winter’s method having very similar values to the dampened Holt’s method. The RMSE value improves but not to the extent that either model match the model using damped Holt’s method.\n\n\n# A tibble: 2 × 9\n  .model           sigma2 log_lik   AIC  AICc   BIC   MSE  AMSE     MAE\n  &lt;chr&gt;             &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;\n1 Additive       1.57      -4406. 8839. 8839. 8905.  1.55  6.04 0.749  \n2 Multiplicative 0.000157  -4368. 8762. 8762. 8827.  1.66  6.78 0.00786\n\n\n\n\n# A tibble: 2 × 10\n  .model         .type          ME  RMSE   MAE    MPE  MAPE  MASE RMSSE  ACF1\n  &lt;chr&gt;          &lt;chr&gt;       &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 Additive       Training 0.00681   1.25 0.749 0.0165 0.761 0.148 0.179 0.327\n2 Multiplicative Training 0.000218  1.29 0.778 0.0210 0.788 0.154 0.185 0.324\n\n\nThe plot here of the 28 day ahead forecast exhibits shallower increases for both models and a narrower set of intervals at 80% and 95%.\n\n\n\n\n\n\n\n\n\n\nModel selection\nHaving previously worked through a number of combinations of exponential smoothing models, both with and without dampening or seasonality, it seems that the damped Holt’s method without seasonality performed best when comparing AICc and RMSE values. However, it’s possible to employ the ETS() function in R to generate a model that minimises the AICc value.\n\n\nSeries: Total \nModel: ETS(M,Ad,N) \n  Smoothing parameters:\n    alpha = 0.9999 \n    beta  = 0.7938542 \n    phi   = 0.8000637 \n\n  Initial states:\n     l[0]      b[0]\n 116.3569 -5.895034\n\n  sigma^2:  1e-04\n\n     AIC     AICc      BIC \n8529.853 8529.925 8560.262 \n\n\nComparisons between this preferred model and the damped Holt’s model from earlier are below:\n\n\n# A tibble: 2 × 9\n  .model                 sigma2 log_lik   AIC  AICc   BIC   MSE  AMSE     MAE\n  &lt;chr&gt;                   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;\n1 R Preferred          0.000130  -4259. 8530. 8530. 8560.  1.33  6.13 0.00697\n2 Damped Holt's method 1.39      -4341. 8695. 8695. 8725.  1.39  6.17 0.689  \n\n\n\n\n# A tibble: 2 × 10\n  .model               .type      ME  RMSE   MAE    MPE  MAPE  MASE RMSSE   ACF1\n  &lt;chr&gt;                &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n1 R Preferred          Trai… 0.00912  1.15 0.684 0.0186 0.698 0.135 0.166 0.0745\n2 Damped Holt's method Trai… 0.00414  1.18 0.689 0.0141 0.702 0.136 0.169 0.0136\n\n\nThe output above tells us the model preferred by R uses Holt’s method where the error is multiplicative (rather than additive as has been used in the examples above), with an additive trend that is dampened. The value for alpha is very high, reflecting how the weight of the past observations decays quite rapidly. The AICc value is the lowest of all the models we have tested above.\nThe forecast of the next 28 days reflects the marginal decline exhibited in some of the other dampened models above. Given that the alpha value is relatively high it is not unsurprising that this model forecasts the mean value to be close to the total 7-day average spend in 2023.\n\n\n\n\n\n\n\n\n\nWe can use cross-validation based on a rolling forecasting origin, starting at the end of 2022 (chosen due to the impact of the pandemic prior to that) and increasing by one step each time. The result of this process is that the model preferred by R performs the best both when comparing AICc and RMSE.\n\n\n# A tibble: 2 × 9\n  .model                 sigma2 log_lik   AIC  AICc   BIC   MSE  AMSE     MAE\n  &lt;chr&gt;                   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;\n1 R Preferred          0.000130  -4259. 8530. 8530. 8560.  1.33  6.13 0.00697\n2 Damped Holt's method 1.39      -4341. 8695. 8695. 8725.  1.39  6.17 0.689  \n\n\n\n\n# A tibble: 2 × 10\n  .model               .type    ME  RMSE   MAE   MPE  MAPE  MASE RMSSE  ACF1\n  &lt;chr&gt;                &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 Damped Holt's method Test  0.841  9.92  7.73 0.492  5.58  1.53  1.43 0.979\n2 R Preferred          Test  0.912  9.77  7.66 0.544  5.53  1.52  1.40 0.979\n\n\nChecking the residuals of R’s preferred model, we can see that the innovation residuals appear to have a constant variance and mean of zero. The histogram exhibits some degree of normality although the peak is a little high. The ACF plot have a number of significant that decay exponentially.\n\n\n\n\n\n\n\n\n\nIn contrast to the damped Holt’s method model, while the residuals have a mean of zero, the variance does appear to increase as we reach the end of 2022 and start 2023. The histogram is slightly left-skewed and peaks so may also fail the normality test. The ACF plot bears some similarity to R’s preferred model with a number of significant lags and before decaying. Given this, R’s preferred model seems to be the better model.\n\n\n\n\n\n\n\n\n\n\n\n\nARIMA modelling\nLooking at the initial plot of data above, it is clear that the data is not stationary and the ACF plot below shows the same data when it is not differenced up to lag 100. The lags remain significant are taking a long time to decay because each is correlated to the previous one. This makes sense when we consider that each daily value in the dataset relates to rolling 7-day average spend so we would expect correlation between the current and previous values.\n\n\n\n\n\n\n\n\n\nTo make the data stationary, I have had to apply a log transformation to stabilise the variance and first order differencing to stabilise the mean. The resulting plot has a number of significant spikes around the time of lockdown restrictions being introduced, but overall resembles white noise.\n\n\n\n\n\n\n\n\n\nThe differenced ACF plot exhibits significant lags up to lag 6 before decaying away.\n\n\n\n\n\n\n\n\n\nIt is also possible to confirm stationarity of this differenced data with a KPSS unit root test, which gives a small test statistic and a p-value of 0.1 and allows us to assume the data is stationary:\n\n\n# A tibble: 1 × 2\n  kpss_stat kpss_pvalue\n      &lt;dbl&gt;       &lt;dbl&gt;\n1     0.139         0.1\n\n\nThe time plot and ACF & PACF plots of the stationary data are show below.\n\n\n\n\n\n\n\n\n\nGiven the data is a 7-day rolling average and that the ACF plot appears to show a sinusodial and seasonal pattern of aproximately 7 days, a seasonal ARIMA model would be appropriate. In order to achieve this, I will let R try to find the best model order. The first is the default stepwise procedure and the second one works harder to search for a better model.\n\nar_fit &lt;- rs3 |&gt; model(stepwise = ARIMA(Total),\n             search = ARIMA(Total, stepwise=FALSE, approx = FALSE))\n\nAs we can from the output here, R has ARIMA(3,1,0)(1,0,1)7 for both models\n\n\n# A mable: 2 x 2\n# Key:     Model name [2]\n  `Model name`                   Orders\n  &lt;chr&gt;                         &lt;model&gt;\n1 stepwise     &lt;ARIMA(3,1,0)(1,0,1)[7]&gt;\n2 search       &lt;ARIMA(3,1,0)(1,0,1)[7]&gt;\n\n\n\n\n# A tibble: 2 × 6\n  .model   sigma2 log_lik   AIC  AICc   BIC\n  &lt;chr&gt;     &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 stepwise  0.955  -1640. 3292. 3292. 3322.\n2 search    0.955  -1640. 3292. 3292. 3322.\n\n\nThe residuals, as shown below, appear to have a constant mean and variance in the time plot and the ACF, whilst show some spikes appears consistent with white noise. However, the model fails the Ljung-Box text for white noise. This model is still left-skewed and peaks a little too high in the histogram, thus failing the normality test.\n\n\n\n\n\n\n\n\n\n\n\n# A tibble: 1 × 3\n  .model lb_stat lb_pvalue\n  &lt;chr&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 search    133.   0.00420\n\n\nAlthough this model does not pass all of the residual tests we can still use it to forecast, bearing in mind the limitations concerning the accuracy of prediction intervals. Forecasts for the next 28 days are shown below.\n\n\n\n\n\n\n\n\n\n\n\nProphet\nFor an alternative approach, I have chosen to use Meta’s Prophet tool for forecasting time series data based on an additive model where non-linear trends are fit with yearly, weekly, and daily seasonality, plus holiday effects.\nIn order to use package, the dataset had to be modified so the date variable was renamed ‘ds’ and the total variable as ‘y’. In addition, Prophet allows for custom holidays to be added to the model to take into account national holidays that occur. The holidays function can also be used to deal with systemic shocks that would impact a time series so as to prevent the trend component capturing any peaks or troughs in the data. As such, I have created an additional tibble that holds the dates for the three UK lockdowns and the period of restrictions in place following the emergence of the omicron variant of COVID-19.\n\n\n# A tsibble: 5 x 2 [1D]\n  ds             y\n  &lt;date&gt;     &lt;dbl&gt;\n1 2020-01-01  114.\n2 2020-01-02  118.\n3 2020-01-03  118.\n4 2020-01-04  116.\n5 2020-01-05  114.\n\n\n\n\n# A tibble: 4 × 5\n  holiday    ds         lower_window ds_upper   upper_window\n  &lt;chr&gt;      &lt;date&gt;            &lt;dbl&gt; &lt;date&gt;            &lt;dbl&gt;\n1 lockdown_1 2020-03-26            0 2020-05-11            0\n2 lockdown_2 2020-11-05            0 2020-12-02            0\n3 lockdown_3 2021-01-05            0 2021-05-17            0\n4 omicron    2021-12-08            0 2022-02-24            0\n\n\nWith the data set up to, I started by modelling the time series with limited changes to the available parameters. However, the changepoint_prior_scale parameter was increased to make the trend more flexible and the seasonality mode changed from additive to multiplicative.\n\nm &lt;- prophet(df, changepoint.prior.scale = 0.3, holidays = lockdowns, seasonality.mode = \"multiplicative\")\n\nfuture &lt;- make_future_dataframe(m, periods = 28)\n\nforecast &lt;- predict(m, future)\n\nplot(m, forecast)+\n    labs(title = \"Prophet multiplicative model\",\n         y=\"Spend (£)\",\n        x=\"Date\")+\n  theme_bw()+\n  theme(plot.title = element_text(face=\"bold\"))\n\n\n\n\n\n\n\n\nThis interactive plot allows for the model to be viewed in more detail:\n\n\n\n\n\n\nUsing Prophet we are able to decompose the model and look at each component separately.\n\n\n\n\n\n\n\n\n\nFinally, using cross-validation we can measure forecast error against historical data in a method akin to a rolling forecast origin used earlier. With Prophet I have chosen to select an initial period of 400 days (i.e. up to early February 2021) and made predictions every 90 days for a forecast horizon of 28 days. Based on the current time series, this corresponded to 9 forecasts.\n\ndf.cv &lt;- cross_validation(m, initial = 400, period = 90, horizon = 28, units = 'days')\n\nOnce computed, we can visualise a range of statistics of prediction performance. In the plot below, the dots show the absolute percentage error and the blue line the mean absolute percentage error over the forecast horizon. Forecast error here remains up to 10% for the first 12 days but then steadily increases to a maximum of around 15% for predictions 28 days out.\n\n\n  horizon       mse      rmse       mae       mape      mdape      smape\n1  3 days  41.00205  6.403284  5.424640 0.05005081 0.04513999 0.05071951\n2  4 days  54.55002  7.385799  6.271378 0.05666009 0.04609069 0.05749919\n3  5 days  67.05754  8.188867  7.034154 0.06205384 0.05589260 0.06309027\n4  6 days  83.74800  9.151393  7.977976 0.06876534 0.06562857 0.07001672\n5  7 days 113.42346 10.650045  9.379767 0.07910440 0.07579380 0.08061358\n6  8 days 148.41528 12.182581 10.719817 0.08878131 0.08017642 0.09073356\n   coverage\n1 0.4355556\n2 0.3644444\n3 0.2933333\n4 0.2133333\n5 0.1422222\n6 0.1111111",
    "crumbs": [
      "Projects",
      "Time Series Analysis"
    ]
  },
  {
    "objectID": "projects/projects2.html",
    "href": "projects/projects2.html",
    "title": "Gender Pay Gap Map",
    "section": "",
    "text": "Introduction\nI used data from the UK Gender Pay Gap Service to highlight the gendered disparity in pay between men and women in the UK.\n\n\nMethodology\nThe dataset has almost 49,000 entries across 27 variables for each of the companies that made a submission. I chose to focus on the mean values in difference between hourly and bonus pay across genders for each entry.\nTo do this, I took the relevant mean values and post codes and essentially performed a lookup with a separate dataset of UK postcodes to obtain the local authority names. This dataframe was combined with a shapefile of UK local authorities. I was then able to summarise the data using the mean value in the differences per local authority.\n\n\nLimitations\nThis approach does have limitations, specifically by using mean values per local authority results in data that is not standardised. Neverthless, the intention of this small project was to put together a visualisation rather than conduct an in-depth analysis of the data.\n\n\nR Code\nThe full code is available on GitHub by clicking here.",
    "crumbs": [
      "Projects",
      "Gender Pay Gap Map"
    ]
  },
  {
    "objectID": "projects/voter_reg/index.html",
    "href": "projects/voter_reg/index.html",
    "title": "Election voter registration",
    "section": "",
    "text": "General election 2024\nThis general election seems like it will be the most significant result since 1997 with Labour gaining a sizeable majority after fourteen years of Conservative rule. Rather than look at polls, I thought it would be interesting to explore who has registered to vote over the past four weeks since the election was called.\nThe Department for Levelling Up, Housing, and Communities (DLUHC) has a performance dashboard with all the relevant data available for this brief analysis.\n\n\nThe last 24 hours\nLet’s start with the last 24 hours before registration closed. The DLUHC dashboard records the number of voter registration applications submitted in a 5-minute period for its live service usage report. I downloaded the data shortly after midnight to get a view of the full day’s applications and the plot looks something like this:\n\n\n\n\n\n\n\n\n\nI wanted to understand what caused some of those spikes and used my own experience and did some investigation to come up with some answers.\n\n6-8am\nIt’s difficult to see on the chart above, but the underlying data shows these occurred in the 5-10 minutes after 6am, 6:30am, 7am, etc. There’s no details on the dashboard suggesting that there is a lag so my assumption here is that this two-hour window is typically when people have just woken up and, after either browsing online media or switching on the TV, have been reminded that June 18th was the last day to register to vote in the general election and did so before getting on with the rest of their day.\n\n\n9-10am\nThere’s a bit of a dip before two further prominent spikes that happen just after 9am and again just after 10am. I couldn’t find details of anything that might have prompted these. So my assumption here is that between the last spike just after 8am and the one at 9am, people are getting ready for work, dropping kids off at school, commuting, etc. So it is only at 9am when when they either start work or, if not working, see a reminder on one of the daytime TV shows to register to vote. This latter point may especially be true for the 10:15am spike in registrations since it occurs just after This Morning starts at 10am.\n\n\nLunchtime\nAt around 12 noon, TikTok sends out a push notification to its users reminding them to register and has been attributed as contributing to the increae in registrations.\n\n\n5pm\nAs many people were probably finishing their workday, Jeremy Corbyn, the now expelled Labour MP and former party leader at the 2019 general election, posted this tweet just after 5pm:\nUnfortunately, a tabloid newspaper has got hold of a music video I recorded in Islington North with an iconic grime artist I've admired for years.They are planning to publish a heavily edited clip, so I'm releasing the full version myself. Watch here: https://t.co/vwNGQN2wqU— Jeremy Corbyn (@jeremycorbyn) June 18, 2024 \nOf course, it was a spurious claim and the link took people to the voter registration site. It was one of a number of similar tweets in the the run up to June 18th and Corbyn received 4 million views, 59K likes, and 15K retweets but hardly registers as a spike in registrations. That said, it occurs just as there is a significant upward trend in numbers.\n\n\n6-8pm\nThe evening is pretty chaotic with evening TV news from 6pm reporting on the election latest and reminding viewers that the day was the last day to register to vote in time for the election. Sky News also published an article about the deadline and, I understand may have sent a notification to users of its app about it:\nThe deadline to register to vote in the general election is today.Here's everything you need to know about how to do it 👇 https://t.co/s98MGwEMw2— Sky News (@SkyNews) June 18, 2024 \nChannel 4 News also hosted a debate with leaders of some of the main parties from 6.30pm - 8pm. At around 7.30pm, the Apple News app on iPhones sent out a notification to users linking to an article about the deadline to register to vote.\n\n\n10.30pm\nRegistrations remain fairly consistent from around 8pm through till 10:30pm when we see a final peak before registrations drop-off by midnight. I’ve not been able to establish what might have caused registration to rise so much other than social media reminders that created a sense of urgency about the imminent deadline. Perhaps, this combined with a captive audience on their phone at bedtime was the right combination to give registrations one final push.\n\n\n\nTotal deadline day registrations\nThe final number of registrations was 629,878 and as you can see from the chart of cumulative registrations, between 7am and midnight, there was a consistent and steady upward trend.\n\n\n\n\n\n\n\n\n\nMy reading of this is that there was no single event that necessarily caused the registrations to spike, but the effect of regular reminders drove momentum. I take this view on the basis that there is no plateau at any point in the day in the cumulative numbers apart from the early hours of the morning.\nHow does this compare to the last election in 2019? Well, I can’t perform a similar analysis of the final day since the data is not available but, according to DLUHC, the total number of applications received on November 26 2019 was 640,815, the equivalent of 1.7% more registrations when compared to 2024.\n\n\n2024 vs 2019 voter registrations\nAlthough a comparison of the two deadline days is not possible, we can compare the number of registrations over the period between the election being announced and the last day voters can register to vote. In 2024 this period lasted 28 days while in 2019 it was 29 days long so I’ve dropped the first day in 2019 ot make the periods line up.\nNevertheless, we see a remarkably similar trend over the four weeks:\n\n\n\n\n\n\n\n\n\nFor both elections, we see an inital flurry of registrations over the first few days before numbers stabilise with similar numbers for each year until final days of the registration period. Apart from this, we see a significant spikes in the fourth week - what could have caused them? There’s not just one reason that can be attributed to these jumps in registrations but here are some of the events that occurred around those dates:\n\nIn 2024, the spike is on day 23 which was June 13, the day when Labour launched its manifesto and ITV held the first debate with representatives of seven parties.\nIn 2019, this spike occurred on day 24 which was November 22, and was the day of a debate on BBC Question Time between the main party leaders and the day after Labour’s manifesto launch. We also see a smaller spike on day 14 - November 12 - of the 2019 election. A number of things happened on that day, including a cyber attack on the Labour party’s IT systems and major flooding in northern England. However, the key political event likely to have caused the increase was the decision by Nigel Farage’s Brexit Party to withdraw candidates in constituencies where the Conservatives had won seats in the 2017 election.\n\n\n\n2024 vs 2019 voter registration demographics\nFinally, let’s take a look at how 2024 has compared to 2019’s voter registration demographics.\n\n20242019\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThere’s a significant decline - by approximately 850K - in 2024 voter registrations by those aged under 35 years old when compared to 2019. In contrast, the number of registrations by those aged over 55 years old has risen by more than 120K. What might we attribute these changes to? I can think of three possible reasons.\nFirst, is the so-called ‘youfquake’ that was associated with Jeremy Corbyn’s leadership of the Labour party which could have inflated the 2019 numbers for under 35 year olds.\nSecond, it seems obvious but as people have aged they have likely shifted into older age groups. Without looking into demographic changes amongst the wider population over the same period its difficult to quantify how much of an impact this has on registrations.\nFinally, I wonder how much disaffection with politics exists in younger voters and how this has impacted registrations. Also, related to this, I question how much apathy there is given the widespread expectation that Labour will form the next government.\nWith less than a week left until the election, I will be fascinated to see how registrations, especially amongst the youth, lead to actual votes.",
    "crumbs": [
      "Portfolio",
      "Election voter registration"
    ]
  }
]